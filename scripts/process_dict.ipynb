{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit0ecf791bd83b4b4eb3b96ac531fee81e",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build dictionary on Phoenix dataset"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util functions"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "def build_dictionary(file):\n",
    "    start = time.time()\n",
    "    lang_model = spacy.load('de_core_news_sm')\n",
    "    end = time.time()\n",
    "    print('load lang_model cost %.3f s'%(end-start))\n",
    "    train = []\n",
    "    # 合并annotation中的语料\n",
    "    df = pd.read_csv(file,sep='|')\n",
    "    for i in range(len(df)):\n",
    "        train.append(df.loc[i]['annotation'])\n",
    "\n",
    "    # Create a dictionary which maps tokens to indices (train contains all the training sentences)\n",
    "    freq_list = Counter()\n",
    "    punctuation = ['_','NULL','ON','OFF','EMOTION','LEFTHAND','IX','PU']\n",
    "    for sentence in train:\n",
    "        sentence = [tok.text for tok in lang_model.tokenizer(sentence) if not tok.text in punctuation]\n",
    "        freq_list.update(sentence)\n",
    "\n",
    "    # 按照词的出现频率建立词典，词频越高索引越靠前\n",
    "    freq_list = sorted(freq_list.items(),key=lambda item:item[1],reverse=True)\n",
    "    dictionary = {}\n",
    "    dictionary['<pad>'] = 0\n",
    "    dictionary['<bos>'] = 1\n",
    "    dictionary['<eos>'] = 2\n",
    "    dictionary['<unk>'] = 3\n",
    "    count = 0\n",
    "    for i,item in enumerate(freq_list):\n",
    "        if item[1] >= 2:\n",
    "            dictionary[item[0]] = count+4\n",
    "            count += 1\n",
    "        else:\n",
    "            dictionary[item[0]] = 3\n",
    "    print(\"Build dictionary successfully!\")\n",
    "    return dictionary\n",
    "\n",
    "def process_sentence(sentence):\n",
    "    punctuation = ['_','NULL','ON','OFF','EMOTION','LEFTHAND','IX','PU']\n",
    "    sentence = [tok.text for tok in lang_model.tokenizer(sentence) \n",
    "        if not tok.text in punctuation]\n",
    "    # sentence = ['<bos>'] +   sentence + ['<eos>']\n",
    "    print(sentence)\n",
    "    indices = [dictionary[word] for word in sentence \n",
    "        if word in dictionary.keys()]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "load lang_model cost 1.232 s\n"
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-af6525d609a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"corpus/train.corpus.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-ae0931886360>\u001b[0m in \u001b[0;36mbuild_dictionary\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "train_file = \"corpus/train.corpus.csv\"\n",
    "dictionary = build_dictionary(train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find OOV words"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "load lang_model cost 1.262 s\nBuild dictionary successfully!\nload lang_model cost 0.955 s\nBuild dictionary successfully!\nload lang_model cost 0.971 s\nBuild dictionary successfully!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[' ',\n 'E+R+Z',\n 'NICHT-WOLKE',\n 'S+H',\n 'C+M',\n 'HARZ',\n 'SECHZIG',\n 'HINREICHEND',\n 'MEIN',\n 'SICHT',\n 'RHEIN-PFALZ',\n 'WOANDERS',\n 'K+U+N+A',\n 'MITBRINGEN',\n 'ZWEIHUNDERT',\n 'WITTERUNG',\n 'ZEHN-STUNDEN',\n 'RUHIGER',\n 'NASE',\n 'HEINS',\n 'SECHSZEHNTE',\n 'ORIENTIEREN',\n 'EINHALB',\n 'NICHT-MOEGEN',\n 'STUFENWEISE',\n 'WEISS',\n 'GAENSEFUSS',\n 'ZWEITAUSEND',\n 'UEBERSPRINGEN',\n 'SEIN',\n 'MAL-SO',\n 'MANNHEIM',\n 'SLOWAKEI',\n 'BEIDE',\n 'MOECHTEN',\n 'ENTTAEUSCHT',\n 'KREISEN',\n 'MENSCHEN',\n 'FROH',\n 'KNOSPE-ABFALLEN',\n 'ERNTE',\n 'O+P+H+E+L+I+A',\n 'ABKUEHLEN',\n 'POSITION',\n 'BILD',\n 'NICHT-WAHRSCHEINLICH',\n 'ANKLICKEN',\n 'AB-SO',\n 'VERLAENGERN',\n 'VESCHWINDEN',\n 'VON-UNTEN',\n 'NACH-NORD',\n 'S+L+Y',\n 'DAS-WARS',\n 'TRINKEN',\n 'SELBST',\n 'ENTSCHEIDUNG',\n 'NICHT-IN-KOMMEND',\n 'SAEGE',\n 'GARTEN',\n 'AUTOBAHN',\n 'ZWISCHEN-MITTE',\n 'NEBEN',\n 'BESTE',\n 'SCHNEEVERWEHUNG']"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "train_file = '/Users/liweijie/SLR/scripts/corpus/train.corpus.csv'\n",
    "train_dict = build_dictionary([train_file])\n",
    "dev_file = '/Users/liweijie/SLR/scripts/corpus/dev.corpus.csv'\n",
    "dev_dict = build_dictionary([dev_file])\n",
    "test_file = '/Users/liweijie/SLR/scripts/corpus/test.corpus.csv'\n",
    "test_dict = build_dictionary([test_file])\n",
    "out_of_vocab = []\n",
    "for k,v in dev_dict.items():\n",
    "    if not k in train_dict.keys():\n",
    "        out_of_vocab.append(k)\n",
    "for k,v in test_dict.items():\n",
    "    if not k in train_dict.keys() and not k in dev_dict.keys():\n",
    "        out_of_vocab.append(k)\n",
    "out_of_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}