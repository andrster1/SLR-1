{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit0ecf791bd83b4b4eb3b96ac531fee81e",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build dictionary on Phoenix dataset"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/liweijie/SLR/scripts/corpus/train.SI5.corpus.csv\",sep='|')\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util functions"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "def build_dictionary(files):\n",
    "    start = time.time()\n",
    "    lang_model = spacy.load('de_core_news_sm')\n",
    "    end = time.time()\n",
    "    print('load lang_model cost %.3f s'%(end-start))\n",
    "    train = []\n",
    "    # 合并annotation中的语料\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file,sep='|')\n",
    "        for i in range(len(df)):\n",
    "            train.append(df.loc[i]['annotation'])\n",
    "\n",
    "    # Create a dictionary which maps tokens to indices (train contains all the training sentences)\n",
    "    freq_list = Counter()\n",
    "    punctuation = ['_','NULL','ON','OFF','EMOTION','LEFTHAND','IX','PU']\n",
    "    for sentence in train:\n",
    "        sentence = [tok.text for tok in lang_model.tokenizer(sentence) if not tok.text in punctuation]\n",
    "        freq_list.update(sentence)\n",
    "\n",
    "    # 按照词的出现频率建立词典，词频越高索引越靠前\n",
    "    freq_list = sorted(freq_list.items(),key=lambda item:item[1],reverse=True)\n",
    "    dictionary = {}\n",
    "    dictionary['<pad>'] = 0\n",
    "    dictionary['<bos>'] = 1\n",
    "    dictionary['<eos>'] = 2\n",
    "    for i,item in enumerate(freq_list):\n",
    "        dictionary[item[0]] = i+3\n",
    "    print(\"Build dictionary successfully!\")\n",
    "    return dictionary\n",
    "\n",
    "def process_sentence(sentence):\n",
    "    punctuation = ['_','NULL','ON','OFF','EMOTION','LEFTHAND','IX','PU']\n",
    "    sentence = [tok.text for tok in lang_model.tokenizer(sentence) \n",
    "        if not tok.text in punctuation]\n",
    "    # sentence = ['<bos>'] +   sentence + ['<eos>']\n",
    "    print(sentence)\n",
    "    indices = [dictionary[word] for word in sentence \n",
    "        if word in dictionary.keys()]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"train.corpus.csv\"\n",
    "dev_file = \"dev.corpus.csv\"\n",
    "dictionary = build_dictionary([train_file,dev_file])\n",
    "lang_model = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find out of vocabulary words"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/Users/liweijie/SLR/scripts/corpus/train.SI5.corpus.csv'\n",
    "train_dict = build_dictionary([train_file])\n",
    "dev_file = '/Users/liweijie/SLR/scripts/corpus/dev.SI5.corpus.csv'\n",
    "dev_dict = build_dictionary([dev_file])\n",
    "test_file = '/Users/liweijie/SLR/scripts/corpus/test.SI5.corpus.csv'\n",
    "test_dict = build_dictionary([test_file])\n",
    "out_of_vocab = []\n",
    "for k,v in dev_dict.items():\n",
    "    if not k in train_dict.keys():\n",
    "        out_of_vocab.append(k)\n",
    "for k,v in test_dict.items():\n",
    "    if not k in train_dict.keys() and not k in dev_dict.keys():\n",
    "        out_of_vocab.append(k)\n",
    "out_of_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/Users/liweijie/SLR/scripts/corpus/train.corpus.csv'\n",
    "train_dict = build_dictionary([train_file])\n",
    "dev_file = '/Users/liweijie/SLR/scripts/corpus/dev.corpus.csv'\n",
    "dev_dict = build_dictionary([dev_file])\n",
    "out_of_vocab = []\n",
    "for k,v in dev_dict.items():\n",
    "    if not k in train_dict.keys():\n",
    "        out_of_vocab.append(k)\n",
    "out_of_vocab"
   ]
  }
 ]
}