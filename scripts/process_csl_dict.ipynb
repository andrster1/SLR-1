{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit0ecf791bd83b4b4eb3b96ac531fee81e",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for preprocess of corpus in CSL dataset"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('dictionary.txt',encoding='utf-8')\n",
    "words = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build isl dictionary"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "282"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "isl_dictionary = {}\n",
    "for word in words:\n",
    "    data = word.rstrip('\\n').split()\n",
    "    index = int(data[0])\n",
    "    token = data[1]\n",
    "    isl_dictionary[token] = index\n",
    "def reverse_dictionary(dictionary):\n",
    "    reverse_dict = {}\n",
    "    for k,v in dictionary.items():\n",
    "        reverse_dict[v] = k\n",
    "    return reverse_dict\n",
    "isl_dictionary['商人']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "目的\n"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build csl dictionary and reverse dictionary"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Build CSL dictionary successfully!\n"
    }
   ],
   "source": [
    "import jieba\n",
    "from collections import Counter\n",
    "def build_csl_dictionary():\n",
    "    annotation_file = open(\"corpus.txt\",'r')\n",
    "    corpus = annotation_file.readlines()\n",
    "    corpus = [sentence.rstrip('\\n').split()[1] for sentence in corpus]\n",
    "    # Create a dictionary which maps tokens to indices (train contains all the training sentences)\n",
    "    freq_list = Counter()\n",
    "    punctuation = ['\\ufeff']\n",
    "    for sentence in corpus:\n",
    "        sentence = [word for word in jieba.cut(sentence) if not word in punctuation]\n",
    "        freq_list.update(sentence)\n",
    "\n",
    "    # 按照词的出现频率建立词典，词频越高索引越靠前\n",
    "    freq_list = sorted(freq_list.items(),key=lambda item:item[1],reverse=True)\n",
    "    dictionary = {}\n",
    "    dictionary['<pad>'] = 0\n",
    "    dictionary['<bos>'] = 1\n",
    "    dictionary['<eos>'] = 2\n",
    "    for i,item in enumerate(freq_list):\n",
    "        dictionary[item[0]] = i+3\n",
    "    print(\"Build CSL dictionary successfully!\")\n",
    "    return dictionary\n",
    "dictionary = build_csl_dictionary()\n",
    "reverse_dict = reverse_dictionary(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'<pad>': 0,\n '<bos>': 1,\n '<eos>': 2,\n '的': 3,\n '是': 4,\n '他': 5,\n '我': 6,\n '你': 7,\n '我们': 8,\n '同学': 9,\n '社会': 10,\n '有': 11,\n '工作': 12,\n '国家': 13,\n '妈妈': 14,\n '哥哥': 15,\n '外祖父': 16,\n '爸爸': 17,\n '目标': 18,\n '朋友': 19,\n '祖父': 20,\n '妹妹': 21,\n '丈夫': 22,\n '新': 23,\n '提高': 24,\n '地位': 25,\n '稳定': 26,\n '基础': 27,\n '幸福': 28,\n '警察': 29,\n '护士': 30,\n '她': 31,\n '邻居': 32,\n '残疾人': 33,\n '公公': 34,\n '婆婆': 35,\n '儿子': 36,\n '裁缝': 37,\n '紧张': 38,\n '改善': 39,\n '民主': 40,\n '团结': 41,\n '毛毯': 42,\n '婚姻': 43,\n '形势': 44,\n '困难': 45,\n '多': 46,\n '地球': 47,\n '情况': 48,\n '好': 49,\n '就业': 50,\n '公务员': 51,\n '商人': 52,\n '解放军': 53,\n '姐姐': 54,\n '模特': 55,\n '工人': 56,\n '保姆': 57,\n '妻子': 58,\n '教师': 59,\n '导演': 60,\n '演员': 61,\n '女朋友': 62,\n '教练': 63,\n '医生': 64,\n '律师': 65,\n '外祖母': 66,\n '园丁': 67,\n '炊事员': 68,\n '表哥': 69,\n '记者': 70,\n '牧民': 71,\n '保育员': 72,\n '弱智人': 73,\n '嫂嫂': 74,\n '画家': 75,\n '知识分子': 76,\n '猎手': 77,\n '保安': 78,\n '邮递员': 79,\n '祖母': 80,\n '聋人': 81,\n '门卫': 82,\n '会计': 83,\n '武警': 84,\n '盲人': 85,\n '编辑': 86,\n '农民': 87,\n '职员': 88,\n '弟弟': 89,\n '向导': 90,\n '岳父': 91,\n '姐夫': 92,\n '刑警': 93,\n '尺子': 94,\n '歪': 95,\n '气氛': 96,\n '效益': 97,\n '环境': 98,\n '局势': 99,\n '现实情况': 100,\n '容易': 101,\n '形成': 102,\n '富强': 103,\n '国民': 104,\n '自由恋爱': 105,\n '捐献': 106,\n '茶壶': 107,\n '褐色': 108,\n '美容': 109,\n '搞清': 110,\n '发挥': 111,\n '优势': 112,\n '扭转局面': 113,\n '现实': 114,\n '学生': 115,\n '任务': 116,\n '安定': 117,\n '行星': 118,\n '月亮': 119,\n '卫星': 120,\n '太阳': 121,\n '恒星': 122,\n '经济': 123,\n '前途': 124,\n '事业成功': 125,\n '他们': 126,\n '摆脱': 127,\n '贫苦': 128,\n '颜色': 129,\n '丰富': 130,\n '经验丰富': 131,\n '剪刀': 132,\n '锋利': 133,\n '被子': 134,\n '破': 135,\n '天气预报': 136,\n '有雨': 137,\n '盆': 138,\n '绿': 139,\n '杯子': 140,\n '橙色': 141,\n '加强': 142,\n '保卫': 143,\n '放弃': 144,\n '引导': 145,\n '他人': 146,\n '成功': 147,\n '结果': 148,\n '圆满成功': 149,\n '手表': 150,\n '坏': 151,\n '牙刷': 152,\n '疏': 153,\n '洗脸盆': 154,\n '空': 155,\n '招聘': 156,\n '岗位': 157,\n '拜访': 158,\n '事情': 159,\n '友谊': 160,\n '深': 161,\n '针线': 162,\n '项链': 163,\n '打火机': 164,\n '天空': 165,\n '没有': 166,\n '星星': 167,\n '小孩子': 168,\n '礼貌': 169,\n '招呼': 170,\n '来': 171,\n '观察': 172,\n '推荐': 173,\n '去': 174,\n '手电筒': 175,\n '电池': 176,\n '平等': 177,\n '毛巾': 178,\n '干': 179}"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "reverse_dict[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "f = open('corpus.txt','r')\n",
    "sentences = f.readlines()\n",
    "count = 0\n",
    "csl_dictionary = {}\n",
    "punctuation = [' ','\\n','\\ufeff']\n",
    "for sentence in sentences:\n",
    "    words = jieba.cut(sentence.rstrip('\\n'))\n",
    "    for word in words:\n",
    "        if word not in csl_dictionary.values() and word not in punctuation and '0' not in word:\n",
    "            csl_dictionary[word] = count\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isIndict(k,dictionary):\n",
    "    for word in dictionary.keys():\n",
    "        if k in word:\n",
    "            return word\n",
    "    return -1\n",
    "isl_in_csl_dictionary = {}\n",
    "for k in csl_dictionary.keys():\n",
    "    word = isIndict(k,isl_dictionary)\n",
    "    if word!=-1:\n",
    "        index = isl_dictionary[word]\n",
    "        isl_in_csl_dictionary[k] = index\n",
    "    else:\n",
    "        print(k)\n",
    "# isl_in_csl_dictionary = sorted(isl_in_csl_dictionary.items(),key=lambda item:item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate subset file for validation\n",
    "subset_index_list = [record[1] for record in isl_in_csl_dictionary]\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "def create_path(path):\n",
    "    if not osp.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "num_class = 500\n",
    "color_video_root = \"/home/liweijie/SLR_dataset/S500_color_video\"\n",
    "skeleton_root = \"/home/liweijie/SLR_dataset/xf500_body_color_txt\"\n",
    "val_list = open(\"../input/subset_val_list.txt\",\"w\")\n",
    "\n",
    "color_video_path_list = os.listdir(color_video_root)\n",
    "color_video_path_list.sort()\n",
    "n = len(color_video_path_list)\n",
    "for i,color_video_path in enumerate(color_video_path_list):\n",
    "    print(\"%d/%d\"%(i,n))\n",
    "    label = color_video_path\n",
    "    abs_color_video_path = osp.join(color_video_root,color_video_path)\n",
    "    color_video_list = os.listdir(abs_color_video_path)\n",
    "    color_video_list.sort()\n",
    "    index = int(label)\n",
    "    if index in subset_index_list:\n",
    "        for color_video in color_video_list:\n",
    "            abs_color_video = osp.join(abs_color_video_path,color_video)\n",
    "            if(osp.isdir(abs_color_video)):\n",
    "                p = color_video.split('_')\n",
    "                person = int(p[0].lstrip('P'))\n",
    "                num_frames = len(os.listdir(abs_color_video))\n",
    "                path = osp.join(color_video_path,color_video)\n",
    "                if not '(' in path:\n",
    "                    path_skeleton = path.rstrip(\"color\")+\"body.txt\"\n",
    "                    abs_path_skeleton = osp.join(skeleton_root,path_skeleton)\n",
    "                    if osp.exists(abs_path_skeleton):\n",
    "                        record = path+\"\\t\"+path_skeleton+\"\\t\"+\\\n",
    "                                            str(num_frames)+\"\\t\"+color_video_path+\"\\n\"\n",
    "                        val_list.write(record)\n",
    "                    else:\n",
    "                        print(\"The skeleton path %s don't exist\"%abs_path_skeleton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_dict[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isl_dictionary"
   ]
  }
 ]
}